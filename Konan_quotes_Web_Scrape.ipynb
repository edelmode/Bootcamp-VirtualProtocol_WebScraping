{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ***Step 1: Introduction and Setup***"
      ],
      "metadata": {
        "id": "t7mYOgHXVcbz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mnwn842UXDC",
        "outputId": "4fff0e19-10c5-4431-d3fc-6d9ce01d8289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.7.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install requests beautifulsoup4 textblob pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Step 2: Import Libraries***"
      ],
      "metadata": {
        "id": "rSGkTgemVmBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "import time"
      ],
      "metadata": {
        "id": "kkxfZQ0jVlYM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Step 3: Data Extraction with Pagination***"
      ],
      "metadata": {
        "id": "FHdQGR6dVsf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Function to extract data from a single page\n",
        "def extract_data_from_page(url):\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36\"\n",
        "    }\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        return []\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Extracting text from all <li> elements under <h2> with specific span structure\n",
        "    raw_data = []\n",
        "    # Find all <h2> elements\n",
        "    headers = soup.find_all('h2')\n",
        "\n",
        "    for header in headers:\n",
        "        # Check if <h2> contains the <span> with the specific class\n",
        "        span = header.find('span', class_='mw-headline')\n",
        "        if span and span.get_text(strip=True) == 'Quotes':\n",
        "            # Find the next sibling <ul> after this <h2>\n",
        "            ul = header.find_next_sibling('ul')\n",
        "            if ul:\n",
        "                list_items = ul.find_all('li')\n",
        "                for item in list_items:\n",
        "                    text = item.get_text(strip=True, separator=' ')\n",
        "                    raw_data.append({'': text})\n",
        "\n",
        "    return raw_data\n",
        "\n",
        "# URL of the page to scrape\n",
        "url = 'https://naruto.fandom.com/wiki/Konan#:~:text=(To%20Jiraiya)%20%22I%20have,believe%20in%20you%2C%20too.%22'  # Replace with the actual URL\n",
        "\n",
        "# Extract data from the single page\n",
        "data = extract_data_from_page(url)\n",
        "\n",
        "# Create DataFrame for structured information\n",
        "df_info_01 = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df_info_01.to_csv('Konan_quotes.csv', index=False)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df_info_01)\n"
      ],
      "metadata": {
        "id": "feibWkQ7Vvp_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19c193d9-0802-4c88-bcf4-d0a7521025bd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                     \n",
            "0   (To Yahiko and Nagato ) \" Yahiko and Nagato… I...\n",
            "1   (To Jiraiya ) \" You have no idea what happened...\n",
            "2   (To Jiraiya) \" I have received the will of god...\n",
            "3   (To Jiraiya) \" That time, you should have list...\n",
            "4   (To Naruto ) \" Nagato believed in you, so I be...\n",
            "5   (To Naruto) \" This time… I hope for you these ...\n",
            "6   (To Tobi ) \" I knew you'd come find me eventua...\n",
            "7   (To Tobi about Naruto) \" He is light personifi...\n",
            "8   (To Tobi) \" Yahiko founded the Akatsuki. The r...\n",
            "9   (To Tobi) \" One question… Madara. Do you under...\n",
            "10  (To Tobi) \" Yahiko and Nagato did what they wa...\n",
            "11  (To Tobi) \" Yahiko and Nagato's will hasn't va...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "#Save the combined DataFrame to a text file with tab delimiters\n",
        "df_info_01.to_csv('konan_qoutes.txt', sep='\\t', index=False)\n",
        "\n",
        "# Download the text file\n",
        "files.download('konan_qoutes.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "fP_nTACjAxnF",
        "outputId": "ee140041-bd7c-45e5-83cd-2f430e1e3405"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4320f50d-1c32-4fb4-8551-a4ee0bdfd95e\", \"konan_qoutes.txt\", 1876)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}